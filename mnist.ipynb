{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/louxiantuo/Tutorial/blob/master/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BML9wXd1ZpB",
        "colab_type": "code",
        "outputId": "3f4a767c-c49f-4834-ddf0-563358ab9876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "#import data.input_data as input_data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets(\"/tmp/data\",one_hot=True)\n",
        "#Paramters\n",
        "learning_rate = 0.001\n",
        "training_iters = 100000\n",
        "batch_size = 128\n",
        "display_step = 10\n",
        "\n",
        "#Network parameters\n",
        "n_input = 784\n",
        "n_classes = 10\n",
        "dropout = 0.8\n",
        "#tf Graph input\n",
        "x = tf.placeholder(tf.float32,[None,n_input])\n",
        "y = tf.placeholder(tf.float32,[None,n_classes])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "#Create model\n",
        "def conv2d(image,w,b):\n",
        "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(image,w,strides=[1,1,1,1],padding='SAME'),b))\n",
        "def max_pool(image,k):\n",
        "    return tf.nn.max_pool(image,ksize=[1,k,k,1],strides=[1,k,k,1],padding='SAME')\n",
        "\n",
        "def dnn(_X,_weights,_biases,_dropout):\n",
        "    _X = tf.nn.dropout(_X,_dropout)\n",
        "    d1 = tf.nn.relu(tf.nn.bias_add(tf.matmul(_X, _weights['wd1']),_biases['bd1']),name='d1')\n",
        "    d2x = tf.nn.dropout(d1,_dropout)\n",
        "    d2 = tf.nn.relu(tf.nn.bias_add(tf.matmul(d2x,_weights['wd2']),_biases['bd2']),name='d2')\n",
        "    dout = tf.nn.dropout(d2,_dropout)\n",
        "    out = tf.matmul(dout,weights['out'])+_biases['out']\n",
        "    return out\n",
        "weights = {\n",
        "    'wd1':tf.Variable(tf.random_normal([784,600],stddev=0.01)),\n",
        "    'wd2':tf.Variable(tf.random_normal([600,480],stddev=0.01)),\n",
        "    'out':tf.Variable(tf.random_normal([480,10]))\n",
        "}\n",
        "biases = {\n",
        "    'bd1':tf.Variable(tf.random_normal([600])),\n",
        "    'bd2':tf.Variable(tf.random_normal([480])),\n",
        "    'out':tf.Variable(tf.random_normal([10])),\n",
        "}\n",
        "#Construct model\n",
        "pred = dnn(x, weights, biases, keep_prob)\n",
        "\n",
        "#Define loss and optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "#Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
        "\n",
        "init = tf.initialize_all_variables()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    step = 1\n",
        "    while step * batch_size < training_iters:\n",
        "        batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
        "        sess.run(optimizer,feed_dict={x:batch_xs,y:batch_ys,keep_prob:dropout})\n",
        "        if step % display_step == 0:\n",
        "            acc = sess.run(accuracy,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.})\n",
        "            loss = sess.run(cost,feed_dict = {x:batch_xs,y:batch_ys,keep_prob:1.})\n",
        "            print(\"Iter \"+str(step*batch_size)+\",Minibatch Loss = \"+\"{:.6f}\".format(loss)+\", Training Accuracy = \"+\"{:.5f}\".format(acc))\n",
        "        step += 1\n",
        "    print(\"Optimization Finished!\")\n",
        "    print(\"Testing Accuarcy : \",sess.run(accuracy,feed_dict={x:mnist.test.images[:256],y:mnist.test.labels[:256]}))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-776c34c9b9d9>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From <ipython-input-3-776c34c9b9d9>:27: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From <ipython-input-3-776c34c9b9d9>:48: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "Iter 1280,Minibatch Loss = 2.205678, Training Accuracy = 0.42188\n",
            "Iter 2560,Minibatch Loss = 1.687716, Training Accuracy = 0.62500\n",
            "Iter 3840,Minibatch Loss = 0.927332, Training Accuracy = 0.75000\n",
            "Iter 5120,Minibatch Loss = 1.585301, Training Accuracy = 0.70312\n",
            "Iter 6400,Minibatch Loss = 1.021366, Training Accuracy = 0.79688\n",
            "Iter 7680,Minibatch Loss = 0.413756, Training Accuracy = 0.85938\n",
            "Iter 8960,Minibatch Loss = 0.458227, Training Accuracy = 0.89062\n",
            "Iter 10240,Minibatch Loss = 0.414232, Training Accuracy = 0.86719\n",
            "Iter 11520,Minibatch Loss = 0.269546, Training Accuracy = 0.91406\n",
            "Iter 12800,Minibatch Loss = 0.325059, Training Accuracy = 0.92188\n",
            "Iter 14080,Minibatch Loss = 0.314053, Training Accuracy = 0.92188\n",
            "Iter 15360,Minibatch Loss = 0.270723, Training Accuracy = 0.90625\n",
            "Iter 16640,Minibatch Loss = 0.227236, Training Accuracy = 0.92188\n",
            "Iter 17920,Minibatch Loss = 0.411037, Training Accuracy = 0.86719\n",
            "Iter 19200,Minibatch Loss = 0.312629, Training Accuracy = 0.87500\n",
            "Iter 20480,Minibatch Loss = 0.314872, Training Accuracy = 0.91406\n",
            "Iter 21760,Minibatch Loss = 0.312788, Training Accuracy = 0.89062\n",
            "Iter 23040,Minibatch Loss = 0.204408, Training Accuracy = 0.94531\n",
            "Iter 24320,Minibatch Loss = 0.212772, Training Accuracy = 0.93750\n",
            "Iter 25600,Minibatch Loss = 0.237364, Training Accuracy = 0.95312\n",
            "Iter 26880,Minibatch Loss = 0.286142, Training Accuracy = 0.90625\n",
            "Iter 28160,Minibatch Loss = 0.281453, Training Accuracy = 0.91406\n",
            "Iter 29440,Minibatch Loss = 0.247775, Training Accuracy = 0.92188\n",
            "Iter 30720,Minibatch Loss = 0.333434, Training Accuracy = 0.89062\n",
            "Iter 32000,Minibatch Loss = 0.361821, Training Accuracy = 0.89062\n",
            "Iter 33280,Minibatch Loss = 0.344032, Training Accuracy = 0.89844\n",
            "Iter 34560,Minibatch Loss = 0.185809, Training Accuracy = 0.93750\n",
            "Iter 35840,Minibatch Loss = 0.183311, Training Accuracy = 0.96094\n",
            "Iter 37120,Minibatch Loss = 0.205532, Training Accuracy = 0.92188\n",
            "Iter 38400,Minibatch Loss = 0.270395, Training Accuracy = 0.90625\n",
            "Iter 39680,Minibatch Loss = 0.303203, Training Accuracy = 0.89062\n",
            "Iter 40960,Minibatch Loss = 0.180261, Training Accuracy = 0.94531\n",
            "Iter 42240,Minibatch Loss = 0.222296, Training Accuracy = 0.91406\n",
            "Iter 43520,Minibatch Loss = 0.292585, Training Accuracy = 0.91406\n",
            "Iter 44800,Minibatch Loss = 0.193802, Training Accuracy = 0.94531\n",
            "Iter 46080,Minibatch Loss = 0.162773, Training Accuracy = 0.94531\n",
            "Iter 47360,Minibatch Loss = 0.191627, Training Accuracy = 0.96094\n",
            "Iter 48640,Minibatch Loss = 0.191757, Training Accuracy = 0.93750\n",
            "Iter 49920,Minibatch Loss = 0.201464, Training Accuracy = 0.91406\n",
            "Iter 51200,Minibatch Loss = 0.081170, Training Accuracy = 0.97656\n",
            "Iter 52480,Minibatch Loss = 0.242308, Training Accuracy = 0.91406\n",
            "Iter 53760,Minibatch Loss = 0.198052, Training Accuracy = 0.93750\n",
            "Iter 55040,Minibatch Loss = 0.175327, Training Accuracy = 0.96094\n",
            "Iter 56320,Minibatch Loss = 0.120730, Training Accuracy = 0.95312\n",
            "Iter 57600,Minibatch Loss = 0.136706, Training Accuracy = 0.95312\n",
            "Iter 58880,Minibatch Loss = 0.184870, Training Accuracy = 0.94531\n",
            "Iter 60160,Minibatch Loss = 0.124721, Training Accuracy = 0.95312\n",
            "Iter 61440,Minibatch Loss = 0.109563, Training Accuracy = 0.96875\n",
            "Iter 62720,Minibatch Loss = 0.162041, Training Accuracy = 0.95312\n",
            "Iter 64000,Minibatch Loss = 0.196153, Training Accuracy = 0.94531\n",
            "Iter 65280,Minibatch Loss = 0.317895, Training Accuracy = 0.91406\n",
            "Iter 66560,Minibatch Loss = 0.173629, Training Accuracy = 0.95312\n",
            "Iter 67840,Minibatch Loss = 0.190690, Training Accuracy = 0.94531\n",
            "Iter 69120,Minibatch Loss = 0.128090, Training Accuracy = 0.96875\n",
            "Iter 70400,Minibatch Loss = 0.318514, Training Accuracy = 0.92969\n",
            "Iter 71680,Minibatch Loss = 0.139403, Training Accuracy = 0.94531\n",
            "Iter 72960,Minibatch Loss = 0.124112, Training Accuracy = 0.95312\n",
            "Iter 74240,Minibatch Loss = 0.194472, Training Accuracy = 0.92188\n",
            "Iter 75520,Minibatch Loss = 0.120510, Training Accuracy = 0.96875\n",
            "Iter 76800,Minibatch Loss = 0.131896, Training Accuracy = 0.95312\n",
            "Iter 78080,Minibatch Loss = 0.125332, Training Accuracy = 0.96094\n",
            "Iter 79360,Minibatch Loss = 0.278625, Training Accuracy = 0.91406\n",
            "Iter 80640,Minibatch Loss = 0.203937, Training Accuracy = 0.94531\n",
            "Iter 81920,Minibatch Loss = 0.155819, Training Accuracy = 0.93750\n",
            "Iter 83200,Minibatch Loss = 0.308079, Training Accuracy = 0.92188\n",
            "Iter 84480,Minibatch Loss = 0.174793, Training Accuracy = 0.93750\n",
            "Iter 85760,Minibatch Loss = 0.156724, Training Accuracy = 0.95312\n",
            "Iter 87040,Minibatch Loss = 0.124914, Training Accuracy = 0.96094\n",
            "Iter 88320,Minibatch Loss = 0.075008, Training Accuracy = 0.97656\n",
            "Iter 89600,Minibatch Loss = 0.151910, Training Accuracy = 0.92969\n",
            "Iter 90880,Minibatch Loss = 0.123898, Training Accuracy = 0.96094\n",
            "Iter 92160,Minibatch Loss = 0.172623, Training Accuracy = 0.96094\n",
            "Iter 93440,Minibatch Loss = 0.164162, Training Accuracy = 0.96094\n",
            "Iter 94720,Minibatch Loss = 0.028337, Training Accuracy = 1.00000\n",
            "Iter 96000,Minibatch Loss = 0.106057, Training Accuracy = 0.97656\n",
            "Iter 97280,Minibatch Loss = 0.256483, Training Accuracy = 0.92188\n",
            "Iter 98560,Minibatch Loss = 0.112750, Training Accuracy = 0.96875\n",
            "Iter 99840,Minibatch Loss = 0.275326, Training Accuracy = 0.92969\n",
            "Optimization Finished!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[{{node Placeholder_2}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-776c34c9b9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimization Finished!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing Accuarcy : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[node Placeholder_2 (defined at <ipython-input-3-776c34c9b9d9>:19) ]]\n\nOriginal stack trace for 'Placeholder_2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-776c34c9b9d9>\", line 19, in <module>\n    keep_prob = tf.placeholder(tf.float32)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 2143, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 6262, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    }
  ]
}